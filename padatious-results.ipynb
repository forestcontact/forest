{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Padatious parser\n",
    "\n",
    "The Padatious parser from Mycroft AI trains a neural network on a set of intents and entity representation, to classify natural language inputs into pre-registered intents. \n",
    "\n",
    "The underlying neural network is FANN, a C library with bindings for Python and other languages. Padatious trains a simple net, with one hidden layer, over the inputs given. Inputs are compiled into regexes, so entities and their positions can be nested within intents.\n",
    "\n",
    "This net is not based on any foundation model and has no world knowledge. This means that any input must match relatively close to the source material. Not great for our desire to have automatic synonym matching, as it results in false negatives. Even word2vec does better in this regard, although it finds lots of false positives.\n",
    "\n",
    "As an example, let's train \"hello\" and \"goodbye\" intents and try some alternative greetings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from padatious import IntentContainer\n",
    "\n",
    "hi_list = ['hey',\n",
    "'hello',\n",
    "'hi',\n",
    "'hello there',\n",
    "'good morning',\n",
    "'good evening',\n",
    "'moin',\n",
    "'hey there',\n",
    "\"let's go\",\n",
    "'hey dude',\n",
    "'goodmorning',\n",
    "'goodevening',\n",
    "'good afternoon',\n",
    "\"what's up\"]\n",
    "\n",
    "bye_list = ['cu'\n",
    "'good by'\n",
    "'cee you later'\n",
    "'good night'\n",
    "'bye'\n",
    "'goodbye'\n",
    "'have a nice day'\n",
    "'see you around'\n",
    "'bye bye'\n",
    "'see you later']\n",
    "\n",
    "container = IntentContainer('intent_cache')\n",
    "\n",
    "container.add_intent('hello', hi_list, reload_cache=True)\n",
    "container.add_intent('goodbye', bye_list, reload_cache=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regenerated goodbye.Regenerated hello.\n",
      "\n",
      "{'name': 'hello', 'sent': ['hello'], 'matches': {}, 'conf': 1.0}\n",
      "{'name': 'hello', 'sent': 'helo', 'matches': {}, 'conf': 0.0}\n",
      "{'name': 'hello', 'sent': 'what up', 'matches': {}, 'conf': 0.6746383452819594}\n",
      "{'name': 'hello', 'sent': 'bye', 'matches': {}, 'conf': 0.0}\n",
      "{'name': 'hello', 'sent': 'good day', 'matches': {}, 'conf': 0.17816539894311617}\n",
      "{'name': 'hello', 'sent': 'later', 'matches': {}, 'conf': 0.0}\n",
      "{'name': 'hello', 'sent': 'error', 'matches': {}, 'conf': 0.0}\n",
      "{'name': 'hello', 'sent': 'help', 'matches': {}, 'conf': 0.0}\n"
     ]
    }
   ],
   "source": [
    "test_list = ['hello', 'helo', 'what up', 'bye', 'good day', 'later', 'error', 'help']\n",
    "for i in test_list:\n",
    "    intent = container.calc_intent(i)\n",
    "    print(intent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the confidence is poor with messages that are subsets of direct inputs (like \"later\" and \"see you later\") and even with a direct match on \"bye\"! It also doesn't deal well with typos like \"helo\", or context-dependent phrases like \"good day\" (which matches the pattern of \"good morning\" but is more often used in English to say \"good bye\").\n",
    "\n",
    "The messages \"error\" and \"help\" should not match to either intent that we've listed, but the classifier can only find intents that have been registered. In some ways this is desirable -- we don't want bots to take commands that don't exist. We can create a \"fallback\" intent to catch unknown commmands like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_list = ['error', 'what?', 'i dont get it', 'can i have a cookie']\n",
    "\n",
    "container.add_intent('fallback', unk_list, reload_cache=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regenerated fallback.\n",
      "{'name': 'hello', 'sent': ['hello'], 'matches': {}, 'conf': 1.0}\n",
      "{'name': 'hello', 'sent': 'helo', 'matches': {}, 'conf': 0.0}\n",
      "{'name': 'hello', 'sent': 'what up', 'matches': {}, 'conf': 0.6746383452819594}\n",
      "{'name': 'hello', 'sent': 'bye', 'matches': {}, 'conf': 0.0}\n",
      "{'name': 'hello', 'sent': 'good day', 'matches': {}, 'conf': 0.17816539894311617}\n",
      "{'name': 'hello', 'sent': 'later', 'matches': {}, 'conf': 0.0}\n",
      "{'name': 'fallback', 'sent': ['error'], 'matches': {}, 'conf': 1.0}\n",
      "{'name': 'hello', 'sent': 'help', 'matches': {}, 'conf': 0.0}\n"
     ]
    }
   ],
   "source": [
    "for i in test_list:\n",
    "    intent = container.calc_intent(i)\n",
    "    print(intent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This still doesn't solve the problem of manually inputting possible commands, though. In `forest/semantic_dist.py` I tested a method using WordNet, a database of synonyms and related words. The goal was to automatically pull the intent data by finding nearby words to our current commands, so the dev only has to decide what the main command is.\n",
    "\n",
    "Let's get the related words for our current examples and a few more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest.semantic_dist import get_synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = ['goodbye', 'hello', 'imagine', 'paint', 'pay', 'ping', 'printerfact', 'uptime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goodbye:\n",
      " ['adieu', 'adios', 'arrivederci', 'auf wiedersehen', 'au revoir', 'bye', 'bye bye', 'cheerio', 'good by', 'goodby', 'good bye', 'goodbye', 'good day', 'sayonara', 'so long', 'farewell', 'word of farewell']\n",
      "hello:\n",
      " ['hello', 'hullo', 'hi', 'howdy', 'how do you do', 'greeting', 'salutation']\n",
      "imagine:\n",
      " ['imagine', 'conceive of', 'ideate', 'envisage', 'think', 'opine', 'suppose', 'imagine', 'reckon', 'guess', 'dream', 'daydream', 'woolgather', 'stargaze', 'envision', 'foresee', 'fantasize', 'fantasise', 'fantasy', 'fantasize', 'fantasise', 'prefigure', 'think', 'visualize', 'visualise', 'envision', 'project', 'fancy', 'see', 'figure', 'picture', 'image', 'visualize', 'visualise', 'suspect', 'create by mental act', 'create mentally', 'expect', 'anticipate']\n",
      "paint:\n",
      " ['paint', 'pigment', 'key', 'paint', 'rouge', 'paint', 'blusher', 'paint', 'paint', 'paint', 'paint', 'acrylic', 'acrylic paint', 'antifouling paint', 'coat of paint', 'distemper', 'enamel', 'encaustic', 'finger paint', 'fingerpaint', 'house paint', 'housepaint', 'oil paint', 'semigloss', 'spray paint', 'water base paint', 'bodypaint', 'charge', 'distemper', 'finger paint', 'fresco', 'shade', 'fill in', 'stipple', 'stipple', 'watercolour', 'watercolor', 'airbrush', 'grain', 'prime', 'ground', 'undercoat', 'repaint', 'repaint', 'coating', 'coat', 'coloring material', 'colouring material', 'color', 'colour', 'space', 'makeup', 'make up', 'war paint', 'create', 'coat', 'surface', 'represent', 'interpret', 'cover']\n",
      "pay:\n",
      " ['wage', 'pay', 'earnings', 'remuneration', 'salary', 'pay', 'give', 'pay', 'pay up', 'ante up', 'pay', 'yield', 'pay', 'bear', 'pay', 'pay off', 'make up', 'compensate', 'give', 'pay', 'devote', 'pay', 'pay', 'pay', 'pay', 'pay', 'combat pay', 'double time', 'found', 'half pay', 'living wage', 'merit pay', 'minimum wage', 'pay envelope', 'pay packet', 'sick pay', 'strike pay', 'take home pay', 'bribe', 'corrupt', 'buy', \"grease one's palms\", 'charge', 'compensate', 'recompense', 'repair', 'indemnify', 'compensate', 'recompense', 'remunerate', 'defray', 'disburse', 'pay out', 'finance', 'foot', 'pick', 'go Dutch', 'kick back', 'overpay', 'pay cash', 'prefer', 'prepay', 'put up', 'contribute', 'redeem', 'pay off', 'refund', 'return', 'repay', 'give back', 'remit', 'spend', 'expend', 'drop', 'subsidize', 'subsidise', 'tithe', 'underpay', 'offer', 'extend', 'liquidate', 'pay off', 'net', 'clear', 'pay off', \"take one's lumps\", \"get one's lumps\", 'pay up', 'ante up', 'pay', 'regular payment', 'give', 'communicate', 'intercommunicate', 'pay', 'gain', 'take in', 'clear', 'make', 'earn', 'realize', 'realise', 'pull in', 'bring in', 'settle', 'think', 'cogitate', 'cerebrate', 'be', 'make', 'digest', 'endure', 'stick out', 'stomach', 'bear', 'stand', 'tolerate', 'support', 'brook', 'abide', 'suffer', 'put up', 'requite', 'repay', 'settle']\n",
      "ping:\n",
      " ['Ping', 'Ping River', 'ping', 'ping', 'pink', 'ping', 'knock', 'ping', 'ping', 'ping', 'sound', 'hit', 'strike', 'impinge on', 'run into', 'collide with', 'sound', 'go', 'sound', 'go', 'reach', 'get through', 'get hold of', 'contact', 'reach', 'get through', 'get hold of', 'contact']\n",
      "uptime:\n",
      " ['uptime', '24/7', 'time period', 'period of time', 'period']\n",
      "fallback ['printerfact']\n"
     ]
    }
   ],
   "source": [
    "container = IntentContainer('intent_cache')\n",
    "\n",
    "no_syns = []\n",
    "for command in commands:\n",
    "    syns = get_synonyms(command)\n",
    "    if len(syns) > 0:\n",
    "        container.add_intent(command, syns, reload_cache=True)\n",
    "        print(command + ':\\n', syns)\n",
    "    else:\n",
    "        no_syns.append(command)\n",
    "\n",
    "print('fallback', no_syns)        \n",
    "container.add_intent('fallback', no_syns, reload_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_commands = [\n",
    "   'hello', \n",
    "   'helo', \n",
    "   'what up', \n",
    "   'bye', \n",
    "   'good day', \n",
    "   'later', \n",
    "   'error', \n",
    "   'help',\n",
    "   'imagine a thing',\n",
    "   'paint a thing',\n",
    "   'draw a thing',\n",
    "   'pigment a thing',\n",
    "   'image of a thing',\n",
    "   'time',\n",
    "   'uptime',\n",
    "   'up period',\n",
    "   'how long have you been up',\n",
    "   'printerfact',\n",
    "   'printer fact',\n",
    "   'printer',\n",
    "   'ping',\n",
    "   'pong',\n",
    "   'pay',\n",
    "   'send payment',\n",
    "   'wallet',\n",
    "   'pay me back',\n",
    "   'cancel',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regenerated goodbye.Regenerated hello.\n",
      "Regenerated ping.Regenerated imagine.Regenerated uptime.\n",
      "\n",
      "\n",
      "\n",
      "Regenerated fallback.\n",
      "Regenerated paint.\n",
      "Regenerated pay.\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "for i in test_commands:\n",
    "    intent = container.calc_intent(i)\n",
    "    responses.append({'name': intent.name, 'sent': intent.sent, 'conf': intent.conf})\n",
    "\n",
    "sorted_responses = sorted(responses, key = lambda x: x['conf'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'hello', 'sent': ['hello'], 'conf': 1.0},\n",
       " {'name': 'goodbye', 'sent': ['bye'], 'conf': 1.0},\n",
       " {'name': 'goodbye', 'sent': ['good', 'day'], 'conf': 1.0},\n",
       " {'name': 'uptime', 'sent': ['uptime'], 'conf': 1.0},\n",
       " {'name': 'fallback', 'sent': ['printerfact'], 'conf': 1.0},\n",
       " {'name': 'ping', 'sent': ['ping'], 'conf': 1.0},\n",
       " {'name': 'pay', 'sent': ['pay'], 'conf': 1.0},\n",
       " {'name': 'uptime', 'sent': 'up period', 'conf': 0.581136967002809},\n",
       " {'name': 'hello',\n",
       "  'sent': 'how long have you been up',\n",
       "  'conf': 0.5648365459442635},\n",
       " {'name': 'pay', 'sent': 'pay me back', 'conf': 0.5195182216860899},\n",
       " {'name': 'imagine', 'sent': 'imagine a thing', 'conf': 0.48457554761404315},\n",
       " {'name': 'paint', 'sent': 'pigment a thing', 'conf': 0.4822043721533956},\n",
       " {'name': 'imagine', 'sent': 'image of a thing', 'conf': 0.4626699964227443},\n",
       " {'name': 'paint', 'sent': 'paint a thing', 'conf': 0.44062001646397364},\n",
       " {'name': 'pay', 'sent': 'send payment', 'conf': 0.4146607694993516},\n",
       " {'name': 'pay', 'sent': 'what up', 'conf': 0.3456195445583059},\n",
       " {'name': 'pay', 'sent': 'time', 'conf': 0.33229434491384896},\n",
       " {'name': 'hello', 'sent': 'printer fact', 'conf': 0.19960761592598483},\n",
       " {'name': 'fallback', 'sent': 'draw a thing', 'conf': 0.1979421001299699},\n",
       " {'name': 'goodbye', 'sent': 'helo', 'conf': 0.0},\n",
       " {'name': 'goodbye', 'sent': 'later', 'conf': 0.0},\n",
       " {'name': 'goodbye', 'sent': 'error', 'conf': 0.0},\n",
       " {'name': 'goodbye', 'sent': 'help', 'conf': 0.0},\n",
       " {'name': 'goodbye', 'sent': 'printer', 'conf': 0.0},\n",
       " {'name': 'goodbye', 'sent': 'pong', 'conf': 0.0},\n",
       " {'name': 'goodbye', 'sent': 'wallet', 'conf': 0.0},\n",
       " {'name': 'goodbye', 'sent': 'cancel', 'conf': 0.0}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sorted_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just under half are parsed correctly. The fallback command isn't catching most of the unknown entities, because it only registers commands that have no synonyms. This could be solved maybe with a hardcoded list of phrases like \"what\" or \"error\" to give it more to work with. Ultimately this only solves some of the problem. Without world knowledge we're limited to whatever synonyms we can find, whether manually or programmatically.\n",
    "\n",
    "The larger problem is that natural language is not a command line. Once people think a bot can understand fuzzy phrasing, they will begin to use casual dialog messages. These can't be extracted from a database like WordNet. Some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'hello', 'sent': 'hi how are you doing', 'matches': {}, 'conf': 0.6703060311786331}\n"
     ]
    }
   ],
   "source": [
    "intent = container.calc_intent('hi how are you doing')\n",
    "print(intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'goodbye', 'sent': 'i want a printer fact', 'matches': {}, 'conf': 0.19702130549922886}\n"
     ]
    }
   ],
   "source": [
    "intent = container.calc_intent('i want a printer fact')\n",
    "print(intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'hello', 'sent': 'send money', 'matches': {}, 'conf': 0.19960761592598483}\n"
     ]
    }
   ],
   "source": [
    "intent = container.calc_intent('send money')\n",
    "print(intent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity recognition\n",
    "\n",
    "Padatious can do slot-filling behavior with entity recognition. This requires registering types of entities withing the intents, like `choose_flavor.intent`: \n",
    "```\n",
    "i want that {flavor} jerky\n",
    "gimme the {flavor}\n",
    "i'll take {flavor} if you have it\n",
    "just {flavor} is fine\n",
    "can i get the {flavor}\n",
    "{flavor} flavor please\n",
    "```\n",
    "\n",
    "and then creating an entity model like `flavor.entity`:\n",
    "\n",
    "```\n",
    "original\n",
    "spicy\n",
    "truffle\n",
    "not4gma\n",
    "insane\n",
    "punjabi\n",
    "garlic\n",
    "teriyaki\n",
    "```\n",
    "\n",
    "This would be a great advantage for bots that need to fill several slots before taking an action. For example, jerkybot needs to make sure it knows the flavor, quantity and size of jerky you're ordering as well as the address to send it to.\n",
    "\n",
    "I prototyped the NLU data in jerkybot-data folder. Let's see how well it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regenerated {quantity}.Regenerated {flavor}.Regenerated {size}.\n",
      "\n",
      "\n",
      "Regenerated {address}.\n",
      "Regenerated affirm.Regenerated greet.Regenerated goodbye.Regenerated deny.Regenerated choose_quantity.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Regenerated choose_flavor.Regenerated botchallenge.\n",
      "Regenerated stop.\n",
      "\n",
      "\n",
      "Regenerated choose_size.Regenerated choose_address.Regenerated order.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from os.path import basename\n",
    "\n",
    "from padatious import IntentContainer\n",
    "\n",
    "container = IntentContainer('intent_cache')\n",
    "\n",
    "for file_name in glob('jerkybot-data/*.intent'):\n",
    "    name = basename(file_name).replace('.intent', '')\n",
    "    container.load_file(name, file_name, reload_cache=True)\n",
    "\n",
    "for file_name in glob('jerkybot-data/*.entity'):\n",
    "    name = basename(file_name).replace('.entity', '')\n",
    "    container.load_entity(name, file_name, reload_cache=True)\n",
    "\n",
    "container.train()\n",
    "\n",
    "def jerkybot(query):\n",
    "    data = container.calc_intent(query)\n",
    "    print(data)\n",
    "    for key, val in data.matches.items():\n",
    "        print('\\t' + key + ': ' + val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'choose_address', 'sent': '{address}', 'matches': {'address': 'i would like some jerky please'}, 'conf': 0.695333292903387}\n",
      "\taddress: i would like some jerky please\n",
      "{'name': 'choose_flavor', 'sent': '{flavor} flavor jerky', 'matches': {'flavor': 'i want insane'}, 'conf': 0.7503358127540253}\n",
      "\tflavor: i want insane\n",
      "{'name': 'choose_address', 'sent': ['my', 'address', 'is', '420', '69', 'th', 'street'], 'matches': {'address': '420 69th street'}, 'conf': 1.0}\n",
      "\taddress: 420 69th street\n",
      "{'name': 'choose_address', 'sent': 'my address is {address}', 'matches': {'address': '1600 pennsylvania ave , washington dc'}, 'conf': 0.7909294250121552}\n",
      "\taddress: 1600 pennsylvania ave , washington dc\n",
      "{'name': 'choose_address', 'sent': '{address}', 'matches': {'address': '420 69 th st is where i live'}, 'conf': 0.7734951919196387}\n",
      "\taddress: 420 69 th st is where i live\n",
      "{'name': 'choose_address', 'sent': '{address}', 'matches': {'address': 'i need 2 bags of the punjabi jerky'}, 'conf': 0.6812262661111277}\n",
      "\taddress: i need 2 bags of the punjabi jerky\n",
      "{'name': 'choose_address', 'sent': '{address}', 'matches': {'address': 'can i have the 8 oz size'}, 'conf': 0.6958106815392294}\n",
      "\taddress: can i have the 8 oz size\n"
     ]
    }
   ],
   "source": [
    "jerkybot('i would like some jerky please')\n",
    "jerkybot('i want insane flavor jerky')\n",
    "jerkybot('my address is 420 69th street')\n",
    "jerkybot('my address is 1600 Pennsylvania Ave, Washington DC')\n",
    "jerkybot('420 69th St is where I live')\n",
    "jerkybot('i need 2 bags of the punjabi jerky')\n",
    "jerkybot('can i have the 8 oz size')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This slot-filling behavior might be useful to us! Unfortunately it's not very reliable and, again, requires a good deal of forethought on how the user will phrase their questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Padatious is more predictable than Rasa NLU pipelines, and requires much less in the way of setup and dependencies. \n",
    "\n",
    "It provides fuzzy matching across command synonyms we can think of or programmatically predict. However, it does not do very well with typos -- string_dist would do much better at telling \"helo\" and \"hello\" to be the same thing, although it would then have trouble distinguishing \"help\". It also doesn't work well with out-of-domain data. Unlike word2vec or other embeddings, it does not contain world knowledge about which words are often used together.\n",
    "\n",
    "Padatious also has slot-filling capabilities, which may be more useful to us than simple intent matching. Unfortunately this requires even more developer attention up front, and would work a lot better if conversations with users were logged to provide more NLU data, which is against our rough plans for private communication with bots.\n",
    "\n",
    "In both cases, we would need a feedback loop between the bot and the user to check if we have received the correct intent and/or entities. If we're already implementing this sort of validation logic, perhaps we should use a more deterministic command-line style model, and put more effort into exposing that predictable behavior to the user.\n",
    "\n",
    "### TL;DR: \n",
    "\n",
    "**Padatious is better than Rasa, but it will require a lot of upfront work by devs and followups with users if we want to have useful NLU data for it to draw from. We might be better off using an argparse-style model and communicating to the user what commands and options are available, rather than trying to interpret them from raw natural language.**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91b513306f197d6d87e99df504cc6c42389073f7cf34d9cee3a2db804ecb1272"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('forest-LyPgfVKv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
